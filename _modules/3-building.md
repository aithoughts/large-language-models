---
title: 构建大型语言模型
---

2023年1月31日
: [建模](../lectures/modeling)
  : **讲座**{: .label .label-purple } **讨论**{: .label .label-green }
: *Percy Liang*
: 1. 分词
  1. RNNs, Transformers
: 讨论论文：
  - [Transformer-XL：超越固定长度上下文的注意语言模型](https://arxiv.org/pdf/1901.02860.pdf)

2023年2月2日
: [训练](../lectures/training)
  : **讲座**{: .label .label-purple } **讨论**{: .label .label-green }
: *Percy Liang*
: 1. 目标函数
  1. 稳定性
  1. 调试
: 讨论论文：
  - [ELECTRA：将文本编码器作为判别器而非生成器进行预训练](https://arxiv.org/pdf/2003.10555.pdf)

2023年2月7日
: [并行主义](../lectures/parallelism)
  : **讲座**{: .label .label-purple } **讨论**{: .label .label-green }
: *Christopher Ré*
: 1. 数据并行主义
  1. 模型并行主义
  1. 管道并行主义
: 讨论论文：
  - [DeepSpeed：为每个人实现极端规模模型训练](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/)

2023年2月9日
: [扩展定律](../lectures/scaling-laws)
  : **讲座**{: .label .label-purple } **讨论**{: .label .label-green }
: *Tatsunori Hashimoto*
: 1. 扩展定律
: 讨论论文：
  - [神经语言模型的扩展定律](https://arxiv.org/pdf/2001.08361.pdf)

2023年2月14日
: [模块化架构](../lectures/selective-architectures)
  : **讲座**{: .label .label-purple } **讨论**{: .label .label-green }
: *Percy Liang*
: 1. 专家混合
  1. 记忆增强（检索）模型
: 讨论论文：
  - [为知识密集型NLP任务提供检索增强生成](https://arxiv.org/pdf/2005.11401.pdf)

2023年2月16日
: [适应](../lectures/adaptation)
  : **讲座**{: .label .label-purple } **讨论**{: .label .label-green }
: *Sang Michael Xie*
: 1. 探测
  1. 微调
  1. 轻量级微调
: 讨论论文：
  - [参数高效提示调整的力量](https://arxiv.org/abs/2104.08691)

2023年2月23日
: [环境影响](../lectures-environment)
  : **讲座**{: .label .label-purple } **讨论**{: .label .label-green }
: *Percy Liang*
: 1. 训练和推理成本
  1. 碳排放
: 讨论论文：
  - [大型神经网络训练的碳排放](https://arxiv.org/pdf/2104.10350.pdf)